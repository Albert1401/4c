{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "import math\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_labels(path):\n",
    "    with open(path, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        return np.fromfile(flbl, dtype=np.uint8).reshape((num,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images(path):\n",
    "    with open(path, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        rows, cols = struct.unpack(\">II\", flbl.read(8))\n",
    "        return np.fromfile(flbl, dtype=np.uint8).reshape((num, rows * cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rx_train = read_images('train-images-idx3-ubyte')\n",
    "ry_train = read_labels('train-labels-idx1-ubyte')\n",
    "rx_test = read_images('t10k-images-idx3-ubyte')\n",
    "ry_test = read_labels('t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(n):\n",
    "    x = np.random.rand(n, 1)\n",
    "    y = (x > 0.5) * 1\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(X):\n",
    "    e = np.mean(X)\n",
    "    s = np.std(X)\n",
    "    return (X - e) / s, lambda x: (x - e) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    return np.eye(1, 10, y)[0]\n",
    "def one_hot_all(Y):\n",
    "    return np.array([one_hot(y) for y in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = rx_train.reshape((len(rx_train), 28 * 28))\n",
    "x_train = rx_train / 255\n",
    "x_test = rx_test / 255\n",
    "\n",
    "# x_train, bnorm = norm(x_train)\n",
    "y_train = one_hot_all(ry_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x))).reshape((len(x),))\n",
    "def sigmoid_prime(x):\n",
    "    s = sigmoid(x)\n",
    "    return (s * (1 - s)).reshape((len(x),))\n",
    "def soft_relu(x):\n",
    "    return np.log(1 + np.exp(x)).reshape((len(x),))\n",
    "def soft_relu_prime(x):\n",
    "    return sigmoid(x)\n",
    "def tanh(x):\n",
    "    return (2 / (1 + np.exp(-2 * x)) - 1).reshape((len(x),))\n",
    "def tanh_prime(x):\n",
    "    return (1 - tanh(x) ** 2).reshape((len(x),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n, activation, activation_prime):\n",
    "        self.n = n\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "        self.c = np.random.rand(n) * 2 - 1\n",
    "    def z(self, x):\n",
    "        return self.w.dot(x) + self.c\n",
    "    def a(self, x):\n",
    "        return self.activation(x)\n",
    "    \n",
    "    def process(self, x):\n",
    "        self.last_z = self.z(x)\n",
    "        self.last_a = self.a(self.last_z)\n",
    "        return self.last_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def J(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred), axis = -1)\n",
    "def J_prime(y_true, y_pred):\n",
    "    return (y_pred - y_true).reshape((len(y_true),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyNN:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.layers = []\n",
    "        \n",
    "    def add(self, layer):\n",
    "        nl1 = layer.n\n",
    "        nl = self.layers[-1].n if self.layers else self.n\n",
    "        layer.w = np.random.rand(nl1, nl) * 2 - 1\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def fit(self, X, Y, batch_size, learning_rate, epochs, decay, moment, verbose):\n",
    "        w_moment = [np.zeros_like(l.w) for l in self.layers]\n",
    "        c_moment = [np.zeros_like(l.c) for l in self.layers]\n",
    "        \n",
    "        if verbose:\n",
    "            epch_widg = widgets.IntText(disabled=True, description = 'epoch:  ')\n",
    "            loss_widg = widgets.FloatText(disabled=True, description = 'loss, %:  ')\n",
    "            progr_widg = widgets.FloatProgress(min = 0, max = 1, step = 0.01, description = 'progress:  ')\n",
    "            display(epch_widg)\n",
    "            display(loss_widg)\n",
    "            display(progr_widg)\n",
    "            \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for _ in range(math.ceil(len(X) / batch_size)):\n",
    "                chs = np.random.choice(len(X), batch_size)\n",
    "                x_batch = X[chs]\n",
    "                y_batch = Y[chs]\n",
    "    \n",
    "                grad_w = [np.zeros_like(l.w) for l in self.layers]\n",
    "                grad_c = [np.zeros_like(l.c) for l in self.layers]\n",
    "                \n",
    "                m = len(self.layers)\n",
    "    \n",
    "                for x, y in zip(x_batch, y_batch):\n",
    "                    y_pred = self.predict(x)\n",
    "                    \n",
    "                    l = self.layers[-1]\n",
    "                    l_sgmp = l.activation_prime\n",
    "    \n",
    "                    delta = [None] * m\n",
    "                    delta[-1] = J_prime(y_true=y, y_pred=y_pred) * l_sgmp(l.last_z)\n",
    "                    \n",
    "                    for i in range(m - 2, -1, -1):\n",
    "                        l = self.layers[i]\n",
    "                        l_sgmp = l.activation_prime\n",
    "                        \n",
    "                        lnext = self.layers[i + 1]\n",
    "                        delta[i] = lnext.w.T.dot(delta[i + 1]) * l_sgmp(l.last_z)\n",
    "    \n",
    "                    #calc grad c\n",
    "                    for g, d in zip(grad_c, delta):\n",
    "                        g += d\n",
    "                    \n",
    "                    #calc grad w\n",
    "                    for i in range(0, m):\n",
    "                        if i == 0:\n",
    "                            aprev = x\n",
    "                        else:\n",
    "                            aprev = self.layers[i - 1].last_a\n",
    "                        l = self.layers[i]\n",
    "                        \n",
    "                        grad_w[i] += delta[i][:, np.newaxis].dot(aprev[:, np.newaxis].T)\n",
    "                        \n",
    "                for l, gr_w, gr_m_w, gr_c, gr_m_c in zip(self.layers, grad_w, w_moment, grad_c, c_moment):\n",
    "                    gr_m_w *= moment\n",
    "                    gr_m_w += (1 - moment) * learning_rate * gr_w / batch_size\n",
    "                    l.w -= gr_m_w\n",
    "                    \n",
    "                    gr_m_c *= moment\n",
    "                    gr_m_c += (1 - moment) * learning_rate * gr_c / batch_size\n",
    "                    l.c -= gr_m_c\n",
    "                    \n",
    "#             clear_output()\n",
    "#             y_pred = np.array([self.predict_d(x) for x in X])\n",
    "#             print('error loss:', J(Y, y_pred).sum(axis = 0))\n",
    "    #                 print('error loss:', (Y != ((y_pred > 0) * 2 - 1)).sum(axis = 0))\n",
    "            learning_rate -= decay\n",
    "            \n",
    "            wsum = sum([np.argmax(y) != self.predict_d(x) for x, y in zip(X, Y)])\n",
    "#             wsum = sum([y != (self.predict(x)[0] > 0) * 2 - 1 for x, y in zip(X, Y)])\n",
    "\n",
    "            if verbose:\n",
    "                epch_widg.value = epoch\n",
    "                loss_widg.value = wsum / len(X) * 100\n",
    "                progr_widg.value = epoch / epochs\n",
    "    \n",
    "    #                 for x1, y1 in zip(cx, cy):\n",
    "    #                     plt.plot(x1[0], x1[1], 'ro' if self.predict(x1) > 0 else 'bo')\n",
    "    #                 plt.show()\n",
    "\n",
    "    def predict(self, a):\n",
    "        for l in self.layers:\n",
    "            a = l.process(a)\n",
    "        return a\n",
    "    \n",
    "    def predict_d(self, x):\n",
    "        y = self.predict(x)\n",
    "        return np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sx_train = x_train\n",
    "sy_train = y_train * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216e1e3601064b4a8c0de0845684ad6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4021342f96c4a31b82b40038c5ee575"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f339f631a1de44b9953c5e9645028871"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn = MyNN(28 * 28)\n",
    "nn.add(Layer(30, tanh, tanh_prime))\n",
    "nn.add(Layer(15, tanh, tanh_prime))\n",
    "nn.add(Layer(10, tanh, tanh_prime))\n",
    "nn.fit(sx_train, sy_train, 200, 0.04, 100, 0, 0.7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00aebea0a84441eb5ff422669d4782a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c344b74ec8c427db0078211d19e2c97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3229b92fe55f4ac69f7761c5fd6296c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.fit(sx_train, sy_train, 200, 0.04, 100, 0, 0.7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adf5f14fcfe4b179659ceef84b1c8e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d52dcd6fee45ebb727a61846fc0afc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075d91cc6ccb4035981f5527e4fca40f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.fit(sx_train, sy_train, 100, 0.05, 100, 0, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, i in zip(x_test, ry_test, range(len(x_test))):\n",
    "    print(y, nn.predict_d(x))\n",
    "    im = x.reshape((28, 28))\n",
    "    plt.imshow(im, plt.cm.Greys)\n",
    "    plt.show()\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071999999999999995"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsum = sum([y != nn.predict_d(x) for x, y in zip(x_test, ry_test)])\n",
    "wsum / len(ry_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c5c468c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open('img.png')\n",
    "x = 255 - np.array(im.resize((28, 28)))[:, :, 0]\n",
    "y = one_hot(int(input()))\n",
    "plt.imshow(x, cmap=plt.cm.Greys)\n",
    "x = x.flatten() / 255\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict_d(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
